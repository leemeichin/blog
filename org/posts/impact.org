#+TITLE: Impact
#+DATE: <2024-04-25 Thu>
#+CATEGORY: work

I've been thinking a lot lately about impact. It hasn't come out of nowhere, but there has for sure been a slow build up of nagging thoughts that have played themselves out as imaginary conversations in my mind when I'm walking to the train station in the morning. Well, when I'm not preocuppied with various self-limiting, self-critical thoughts because I've been so thoroughly worn out that I struggle to hold them back, that is.

At risk of coming across cynical, my experience of software engineering in the web/SaaS space seems like it can be boiled down to automating data entry and then rendering the result in a palatable form. Converting SQL to HTML or JSON if you will. 

I'm well aware of how reductive that take is, it's not intended to be taken seriously, but that's sometimes what it feels like. Most of the time you're taking something in the shape of a CMS (content management system), CRM (customer relation management system), or an eCommerce platform, and then complicating it with novel architecture to spice things up a bit.

I kid. It's not all like that.

I consider myself to be passionate about programming but not in love with it. My passion takes the form of a desire for great craftmanship, living in the blurred boundary between perfection and pragmatism. Too much or too little of either is less than ideal, but the ratio of those ingredients shifts as the business matures and finds its place in the market.

What I'm building up to here is the /internal/ impact of the work you do, which can shape the culture and work ethic of the company you work in. It is absolutely trivial to deliver work as a software engineer that solves a business need--or delivers value--entirely at the expense of the productivity of the wider engineering team and even other teams you work with. Call it the YOLO school of pragmatic thought which misapplies the concept of prototypical, proof-of-concept style development to production ready systems.

#+BEGIN_ASIDE
If someone in tech ever tells you a solution is temporary, expect it to be permanent
#+END_ASIDE

This isn't to say that nobody can make mistakes or they have to get the solution correct the first time. That's impossible and unfair and, as they say, anything can be a poison: it's all about the dosage. Too much and you have a bottleneck, too little and you're probably failing to move the needle. If you can't experiment, get things wrong, or incur some tech debt or opportunity cost along the way, then what does that mean in terms of innovation?

It's important question though, for me. "What is the impact of my work within the team?" I hope it's positive and I hope the bad calls I make are outweighed by the good ones. If I can get the deployment build down from 10 minutes to 4 minutes, then there is no direct impact to the user there, but my team mates are a hell of a lot happier and we're also spending less money on CI time.

My favourite example of this is from my time back at Typeform. For reasons I don't remember I felt a lot of empathy for the customer success team--perhaps because Typeform's onboarding way back then involved spending 2 weeks with customer success before moving on to your actual position, which I think was fucking incredible in terms of understanding who exactly you are going to be building software for--but found myself in the position of leading an internal project to support them. We were just going to build a new admin panel basically, and the challenge was to build one that could easily be extended in the context of a fairly young microservice environment. Priorities were set in terms of support-hours saved, which we determined by collecting anecdotal evidence from the success team and combining it with data from Zendesk, and within mere weeks we'd racked up a saving of 50 hours a week in support time.

For me, that was internal work with incredibly high impact. We found a way to get it done and I'm sure the people who had to maintain it in future had their fair share of WTF moments, but we'd considered the needs of other engineers and what it'd be like for us to hand over to them, and we considered the needs of customer success. It was great to hear, some years later, that the system was still running. It was designed to be easy to replace in case someone had a better idea.

More than that, it also facilitated the switch from quality engineering to software development for some in the team. Incredible.

-----

What about /external/ impact, then? The end result of the work. The outcome.

This is a difficult one to discuss because, at least for me, it makes me wonder how good a judge I am of values. Values for a business are like character for a friend.

#+BEGIN_ASIDE
External impact is by and large social impact too. Environmental impact is also social impact, because for environmental impact to stick you need society on board with it, and it's often delivered through social means.
#+END_ASIDE

For example, I joined Babylon Health because I was thrilled by the prospect of working in healthcare, doing work that has a good cause and a positive social impact. I didn't realise that my day to day job for almost two years would be rewriting Ruby code in Java. Replatforming, we called it. The experience was invaluable but the lack of impact left me feeling unfulfilled, because rewriting Ruby code in Java didn't feel like I was contributing to the social impact. 

My cynical jab about the nature of programming for SaaS earlier on comes from a place of yearning, I suppose. What am I doing with my life? That kind of thing.

I left Friday (now Friday Pulse) after about a year because I didn't know what I wanted long term, but even though that business has taken various shapes over the years since, I read the founder's posts on LinkedIn and think "damn, whatever happened he hasn't stopped, he's still on to something, still has complete conviction about building healthier workplaces." Friday was, and still is I imagine, basically an answer to those employee engagement survey tools that are basically ignored by leadership unless they're overwhelmingly positive.

Hopin is an interesting one, being a COVID-era darling attracting impossible investment. Absolutely loved it there. Far from perfect, and we went through a lot. The impact at the time was that we built virtual event spaces and used them at scale at the time when lockdowns were in force and nobody could do any of it in person. Immense positive social impact, making the best of a bad situation, connecting a whole world of people to build it completely remotely (albeit at stupid scale, something I doubt will ever happen again). I think this one flew under the radar for a lot of people - it went from 0 to 4 *billion* in about 12 months, 0 to 1200 staff in the same time.

I don't think any of that left a mark on the world, which is a shame, but it certainly left a mark on me. My experiences at Hopin and doing /hyper/scale will be in another post soon.

----

The thing with impact is that it can't be assumed to be positive. Impact is a consequence, or a side-effect, an externality... it knows nothing about good or bad.

This is kind of my sticking point now: what am I doing that can help make the world around me better? Directly or indirectly. Much of the work of a software engineer entails the automation of otherwise manual, human driven work. It can be argued that delegating to tech frees up a person to do other things, but this often comes at the cost of people's employment and their livelihood that depends on it.

#+BEGIN_QUOTE
"Some of you will be laid off, but that's a sacrifice I'm willing to make."
#+END_QUOTE

This is where we have to talk about AI. Automating data-entry has been a thing for a long time; /computers/ used to be women in offices who would /compute/ things (often tedious mathematical calculations), now they are machines. 

AI promises that it can accelerate the automation of plenty of other things, it's as magical now as it was 6 years ago when it was being used as an aspirational buzzword for pattern matching and Bayesian inference (both of which have their place, don't get me wrong).

So, what /exactly/ do you want to automate, using AI?

AI Workers and Agents seem to be popular, basically creating a skeuomorph of a human via an LLM with a conversational UI slapped on top of it.

AI content generation is another. It's impressive, seeing AI convert a prompt into multimedia: images, text, songs, consent-defying porn...

Deception. AI is great for that, you can go into an interview and read answers to questions from GPT, which is cheaper than wearing an earpiece and having answers fed to you off camera. (Yes, this actually did happen)

Information: it is trivial to convince an LLM to produce false information with complete confidence and conviction. A year ago with GPT3 I asked about the 'Great Beefcliff Crisis of 2003' and it responded with absolute certainty that there was a drastic shock in the US meat economy at the time, leading to an abundance of cow meat and the afore mentioned 'Beef Cliff'. It hallucinated URLs to non-existent posts on the New York Times - they were all obviously 404.

#+BEGIN_ASIDE
The thing is, you don't need an LLM to manipulate people on the internet, Google and Facebook in particular have crafted complex engagement and targeting algorithms that have opened the floodgates to people and companies with bad intentions. The technology of the decadent West being turned on itself. There's no need to use AI when you can target propaganda and be guided along through the process in the promise of engagement and ad revenue, because the money is speaking louder than the ethics.
#+BEGIN_ASIDE

More often than not the problem is adequately solved without even thinking about AI. But it broadens the horizon of your thinking.

Consider music for a moment. Every advancement in the technology of music has only served to make the creation of music more available to the average person, and over time the average person changes as a result. 

A lot of those advancements can be attributed to happenstance, but automation found a way in there. You want more than one arpeggio at the same time? You got one. That's commodity now though, it wasn't back when The Who were using it for Baba O'Riley.

It still takes skill to run the synth. The introduction of it wasn't a net loss on society, it just advanced it, diversified it, made it more /interesting/.

----

Where am I going with this? I have no idea, I've been writing it on the fly, that's kinda my thing.

I feel like a lot of the high level thinking in this new era of AI is in the evaluation stage - we can't know yet if it's good or bad for society because it's too young.

I think suno.ai runs the risk of devaluing music, but at the same time it makes the process of making music more available - the novelty of it wears off really quickly unless you are serious about trying out lyrics and sounds, and that makes it more of a musician's tool. I'm a shit musician but I known my way around words, and playing out my ideas with an AI support track has provided to my voice a sound I have lacked., even if the sound is totally unpredictable and basically the average of everything.

That's what AI is gonna be really, isn't it? Same as everything else. The average of everything. The middle of the road. It's good enough and it's bad enough, awful to nobody and awesome to everyone.

-------

For me, especially at this point in time where I've started to think about it, it means I need, want to be, positive, and socially based. The purpose of my work has to push the cause of humanity forward but more and more I feel it has to start from the top and not the bottom, because leadership and culture comes from the top. Engineering, company culture, whatever...it has to mean something, and the social impact has to be a net gain.

I don't think it's a hard problem. It's people who make it hard.